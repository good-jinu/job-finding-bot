from datetime import datetime
from langchain_core.prompts import PromptTemplate
from src.core.llm.providers import get_job_analysis_model
from src.core.schemas.job_analysis import JobAnalysisState
from src.core.database.job_postings import get_unread_job_posting
from src.core.file_storage.paths import FileStoragePaths
from src.core.file_storage.file_manager import FileManager
from src.core.database.users import get_all_users
import random


# Initialize file storage
file_paths = FileStoragePaths()
file_manager = FileManager(file_paths)


async def scrape_job_details_node(state: JobAnalysisState) -> JobAnalysisState:
  """ì±„ìš©ê³µê³  í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ì„œ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
  print("--- Reading Job Details from Content File ---")

  try:
    # Get job posting from database
    job_posting = get_unread_job_posting()

    if not job_posting:
      print("No unread job posting found")
      state["detailed_job_info"] = state["job_description"]
      return state

    # Read content from content_doc file
    if job_posting.content_doc:
      content_file = file_paths.get_job_content_path(job_posting.content_doc)
      text_content = file_manager.read_file_sync(content_file)
      if text_content:
        state["detailed_job_info"] = text_content
        print(f"Successfully read job details from {content_file}")
      else:
        print(f"Content file not found: {content_file}")
        state["detailed_job_info"] = job_posting.description
    else:
      # Fallback to description if content_doc is not provided
      state["detailed_job_info"] = job_posting.description

  except Exception as e:
    print(f"Error reading job details: {e}")
    state["detailed_job_info"] = state.get("job_description", "")

  return state


def load_resume_node(state: JobAnalysisState) -> JobAnalysisState:
  """ì´ë ¥ì„œ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
  print("--- Loading Resume ---")

  # Get a random user and their resume file
  users = get_all_users()
  if not users:
    state["resume_content"] = "ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤."
    return state

  # Select random user if no specific user_id is provided
  if hasattr(state, "user_id") and state.user_id:
    selected_user = next((user for user in users if user.id == state.user_id), None)
    if not selected_user:
      selected_user = random.choice(users)
  else:
    selected_user = random.choice(users)

  if selected_user and selected_user.resume_file:
    resume_path = file_paths.get_resume_path(selected_user.resume_file)
    resume_content = file_manager.read_file_sync(resume_path)
    if resume_content:
      state["resume_content"] = resume_content
      state["user_id"] = selected_user.id  # Store which user's resume we used
      print(f"Loaded resume for user {selected_user.name} from {resume_path}")
    else:
      state["resume_content"] = "ì´ë ¥ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
      print("Resume file not found")
  else:
    state["resume_content"] = "ì´ë ¥ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
    print("No resume file available")

  return state


async def analyze_job_fit_node(state: JobAnalysisState) -> JobAnalysisState:
  """ì±„ìš©ê³µê³ ì™€ ì´ë ¥ì„œì˜ ì í•©ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
  print("--- Starting Job Fit Analysis ---")

  # LLM ì„¤ì • - providersì—ì„œ ê°€ì ¸ì˜¤ê¸°
  llm = get_job_analysis_model()

  prompt = PromptTemplate(
    template="""
ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì±„ìš© ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„ìš©ê³µê³ ì™€ ì´ë ¥ì„œë¥¼ ë¶„ì„í•˜ì—¬ 
ì í•©ì„±ì„ í‰ê°€í•˜ê³  ìƒì„¸í•œ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ì±„ìš©ê³µê³  ì •ë³´:
{job_info}

## ì´ë ¥ì„œ:
{resume}

## ë¶„ì„ ìš”êµ¬ì‚¬í•­:
1. ì§€ì›ìì˜ ê°•ì ê³¼ ì•½ì  ì‹ë³„
2. ë³´ì™„í•´ì•¼ í•  ì ê³¼ ê°œì„  ë°©ì•ˆ ì œì‹œ
3. ì§€ì› ì‹œ ê°•ì¡°í•´ì•¼ í•  í¬ì¸íŠ¸ ì œì•ˆ
4. ì „ë°˜ì ì¸ ì í•©ì„± í‰ê°€

ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì„œ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

# ì±„ìš©ê³µê³  ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ì±„ìš©ê³µê³ **: [ì§ë¬´ ì œëª©]
- **íšŒì‚¬**: [íšŒì‚¬ëª…]
- **ê·¼ë¬´ì§€**: [ìœ„ì¹˜]

## âœ… ì§€ì›ì ê°•ì 
[ì§€ì›ìì˜ ê°•ì ì„ ìƒì„¸íˆ ë¶„ì„]

## âš ï¸ ë³´ì™„ í•„ìš” ì‚¬í•­
[ë³´ì™„í•´ì•¼ í•  ì ë“¤ì„ ì œì‹œ]

## ğŸ”§ ê°œì„  ë°©ì•ˆ
[ê°œì„  ë°©ì•ˆë“¤ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì•ˆ]

## ğŸ’¡ ì§€ì› ì „ëµ
[ì§€ì› ì‹œ í™œìš©í•  ì „ëµì  ì œì•ˆ]

## ğŸ“ ì¢…í•© í‰ê°€
[ì „ë°˜ì ì¸ ì í•©ì„± í‰ê°€ ë° ê²°ë¡ ]
""",
    input_variables=["job_info", "resume"],
  )

  try:
    chain = prompt | llm
    result = await chain.ainvoke(
      {"job_info": state["detailed_job_info"], "resume": state["resume_content"]}
    )
    print("Job analysis completed successfully")
    state["analysis_result"] = str(result.content)

  except Exception as e:
    print(f"Error in job analysis: {e}")
    state["analysis_result"] = f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

  return state


def generate_report_node(state: JobAnalysisState) -> JobAnalysisState:
  """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
  print("--- Generating Analysis Report ---")

  try:
    analysis_data = state["analysis_result"]

    print(f"Analysis result: {analysis_data[:100]}...")  # Show first 100 chars

    # Use the analysis result as-is since it's already formatted text
    report = f"""# ì±„ìš©ê³µê³  ë¶„ì„ ë³´ê³ ì„œ

{analysis_data}

---
*ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""

    state["report_content"] = report

    # íŒŒì¼ë¡œ ì €ì¥
    output_path = file_paths.get_output_report_path("job_analysis")
    file_manager.write_file_sync(output_path, report)

    print(f"Report saved to: {output_path}")

  except Exception as e:
    print(f"Error generating report: {e}")
    state["report_content"] = "ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

  return state
